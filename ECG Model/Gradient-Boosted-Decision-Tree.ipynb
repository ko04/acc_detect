{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Data : \n",
    "filename = \"\" #Replace with cleaned and pre-processed data\n",
    "actorDF = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is helpful if we have categorical data (anything that's not a number)\n",
    "#I don't think we have that but I'll still include the code to handle it\n",
    "\n",
    "#If any other columns need to be dropped include it here\n",
    "X = actorDF.drop(['label'],axis=1)\n",
    "y = actorDF.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is if we have categorical data\n",
    "\n",
    "for c in X.columns:\n",
    "    col_type = X[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        X[c] = X[c].astype('category')\n",
    "    if col_type == 'float64':\n",
    "        X[c] = X[c].astype('int64')\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the data into train and test with an 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=320, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows us to avoid overtraining and we do not need to optimise the number of trees\n",
    "fit_params={\"early_stopping_rounds\":10, \n",
    "            \"eval_metric\" : 'logloss', \n",
    "            \"eval_set\" : [(X_test,y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            'feature_name': 'auto', # that's actually the default\n",
    "            'categorical_feature': 'auto' # that's actually the default\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 1000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(num_leaves= 15, max_depth=-1, \n",
    "                         random_state=314,  \n",
    "                         metric='None', \n",
    "                         n_jobs=4, \n",
    "                         n_estimators=1000,\n",
    "                         colsample_bytree=0.9,\n",
    "                         subsample=0.9,\n",
    "                         learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#force larger number of max trees and smaller learning rate\n",
    "clf.fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy {:.4f}'.format(clf.score(X_train,y_train)))\n",
    "print('Testing accuracy {:.4f}'.format(clf.score(X_test,y_test)))\n",
    "\n",
    "lgb.plot_importance(clf)\n",
    "lgb.plot_metric(clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
